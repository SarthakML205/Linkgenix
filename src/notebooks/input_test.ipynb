{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4df7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image from: D:\\LinkGenix\\src\\notebooks\\assests\\website-sitemap (1).png\n",
      "Using model: gemini-1.5-pro-latest\n",
      "Sending prompt: What objects are in this image? Describe the scene.\n",
      "\n",
      "--- Gemini Response ---\n",
      "The image is a flowchart or sitemap, likely for an e-commerce website. It visually represents the different pages and user journeys within the site, particularly focusing on the shopping and classifieds posting processes.  It uses rectangular boxes connected by lines to illustrate the flow and hierarchy of information.\n",
      "\n",
      "The main categories, branching directly from the \"Home\" page, are:\n",
      "\n",
      "* **Shop:** This section deals with the standard purchasing process. It leads to \"Product List\", then \"Product Detail Page\", \"Cart\", and finally \"Checkout\".  At the cart stage, the flow diverges based on whether the user is \"Logged In\" or \"Not Logged In,\" with the latter path leading to a \"Log In / Register\" page.\n",
      "\n",
      "* **Classifieds:** This branch focuses on posting classified advertisements.  It includes pages for \"Classifieds Success Stories\", and \"Post a Classified\".  The posting process further branches depending on login status (\"Logged In\" or \"Not Logged In\"), with the \"Not Logged In\" path requiring a \"Log In / Register\" step.  After posting, a template is used, a confirmation email is sent, and the post can be either \"Rejected\" or \"Approved,\" each leading to a corresponding email notification.\n",
      "\n",
      "* **Sell:** This section likely caters to sellers of products, different from the classifieds. It branches depending on whether the user is \"Logged In\" to a seller account or not. If \"Not Logged In\" the user is prompted to \"Log In / Register.\" A logged in seller will be directed to their \"Seller's Account,\" and then a \"Template\" page, presumably for creating product listings.\n",
      "\n",
      "* **My Account:** A standard account management section.\n",
      "\n",
      "* **Login:** Page for logging into the website.\n",
      "\n",
      "* **Create an Account:** Page for creating a new account.\n",
      "\n",
      "* **Social Media:** Links to the website's social media presence.\n",
      "\n",
      "* **About Us:**  Information about the company.\n",
      "\n",
      "* **Customer Support:** Help and support resources.\n",
      "\n",
      "* **Blog:**  The website's blog.  It includes links to \"Testimonials,\" \"Glossary,\" \"FAQs,\" \"Become a Seller,\" \"Return Policy,\" and \"Shipping Policy.\"\n",
      "\n",
      "The different colors of the boxes likely represent different categories or functionalities within the site.  For example, the shop flow is in green, classifieds in blue, sell options in taupe, and the about us, customer support, and blog sections are in shades of purple and red/pink. Yellow/orange often highlights decision points based on login status.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import PIL.Image # For image handling\n",
    "import os\n",
    "import sys\n",
    "# Add project root to sys.path to find config\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..')) # Adjust based on notebook location relative to root\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "import config # Import the config module\n",
    "\n",
    "# --- Configuration ---\n",
    "# API Key is now loaded in config.py\n",
    "if not config.GOOGLE_API_KEY:\n",
    "    raise ValueError(\"API key not found. Please check your .env file and config.py.\")\n",
    "\n",
    "genai.configure(api_key=config.GOOGLE_API_KEY)\n",
    "\n",
    "# --- Function to Send Image and Prompt ---\n",
    "# Use default model from config, allow override\n",
    "def ask_gemini_about_image(image_path: str, text_prompt: str, model_name: str = config.DEFAULT_GEMINI_FLASH_MODEL):\n",
    "    \"\"\"\n",
    "    Sends an image and a text prompt to the specified Gemini model.\n",
    "\n",
    "    Args:\n",
    "        image_path: Path to the image file.\n",
    "        text_prompt: The question or instruction related to the image.\n",
    "        model_name: The Gemini model to use (defaults to config.DEFAULT_GEMINI_FLASH_MODEL).\n",
    "\n",
    "    Returns:\n",
    "        The text response from the model, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    print(f\"Loading image from: {image_path}\")\n",
    "    print(f\"Using model: {model_name}\")\n",
    "    print(f\"Sending prompt: {text_prompt}\")\n",
    "\n",
    "    try:\n",
    "        # Load the image using PIL\n",
    "        img = PIL.Image.open(image_path)\n",
    "\n",
    "        # Select the Gemini model\n",
    "        model = genai.GenerativeModel(model_name)\n",
    "\n",
    "        # Send the prompt and image to the model\n",
    "        response = model.generate_content([text_prompt, img])\n",
    "\n",
    "        # Handle potential safety blocks or empty responses\n",
    "        if not response.parts:\n",
    "             print(\"Warning: Received an empty response. This might be due to safety filters.\")\n",
    "             print(f\"Prompt Feedback: {response.prompt_feedback}\")\n",
    "             return None\n",
    "        if response.candidates[0].finish_reason.name != \"STOP\":\n",
    "             print(f\"Warning: Generation finished unexpectedly. Reason: {response.candidates[0].finish_reason.name}\")\n",
    "\n",
    "        return response.text\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Image file not found at '{image_path}'\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Use image path from config\n",
    "    image_file = config.DEFAULT_IMAGE_PATH \n",
    "\n",
    "    # The question you want to ask about the image\n",
    "    prompt = \"What objects are in this image? Describe the scene.\"\n",
    "\n",
    "    # Choose the model using config defaults\n",
    "    model_choice = config.DEFAULT_GEMINI_PRO_MODEL # Or use Pro from config\n",
    "\n",
    "    # Check if the image file exists before calling\n",
    "    if os.path.exists(image_file):\n",
    "        result = ask_gemini_about_image(image_file, prompt, model_choice)\n",
    "\n",
    "        if result:\n",
    "            print(\"\\n--- Gemini Response ---\")\n",
    "            print(result)\n",
    "        else:\n",
    "            print(\"\\nFailed to get a response from Gemini.\")\n",
    "    else:\n",
    "        print(f\"Error: The file '{image_file}' does not exist. Please check config.py.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3095f2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import tempfile\n",
    "from PIL import Image\n",
    "import io\n",
    "import sys\n",
    "# Add project root to sys.path if not already done\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "import config # Import the config module\n",
    "\n",
    "# Use default DPI from config, allow override\n",
    "def pdf_to_screenshots_for_spaces(uploaded_pdf, output_dir=None, dpi=config.DEFAULT_PDF_DPI, page_range=None):\n",
    "    \"\"\"\n",
    "    Convert PDF pages to PNG images, designed for Hugging Face Spaces.\n",
    "    \n",
    "    Args:\n",
    "        uploaded_pdf: File object from Streamlit/Gradio upload or bytes data\n",
    "        output_dir: Optional directory to save files (temp dir used if None)\n",
    "        dpi: Resolution for the images (defaults to config.DEFAULT_PDF_DPI)\n",
    "        page_range: Tuple of (start_page, end_page) or None for all pages\n",
    "        \n",
    "    Returns:\n",
    "        List of PIL Image objects and their paths if saved\n",
    "    \"\"\"\n",
    "    # Create temp directory if no output specified\n",
    "    if output_dir is None:\n",
    "        output_dir = tempfile.mkdtemp()\n",
    "        print(f\"Created temporary directory: {output_dir}\")\n",
    "    elif not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Handle file object or bytes\n",
    "    temp_pdf_path = os.path.join(output_dir, \"temp_pdf.pdf\")\n",
    "    \n",
    "    # Save uploaded file to temp location if it's not already a path\n",
    "    if isinstance(uploaded_pdf, (bytes, io.BytesIO)):\n",
    "        # It's bytes data\n",
    "        with open(temp_pdf_path, \"wb\") as f:\n",
    "            if isinstance(uploaded_pdf, bytes):\n",
    "                f.write(uploaded_pdf)\n",
    "            else:\n",
    "                f.write(uploaded_pdf.read())\n",
    "        pdf_path = temp_pdf_path\n",
    "    elif hasattr(uploaded_pdf, 'read'):\n",
    "        # It's a file-like object\n",
    "        with open(temp_pdf_path, \"wb\") as f:\n",
    "            f.write(uploaded_pdf.read())\n",
    "        pdf_path = temp_pdf_path\n",
    "    else:\n",
    "        # Assuming it's already a file path\n",
    "        pdf_path = uploaded_pdf\n",
    "    \n",
    "    # Open the PDF\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening PDF: {e}\")\n",
    "        return []\n",
    "    \n",
    "    # Determine page range\n",
    "    if page_range:\n",
    "        start_page, end_page = max(0, page_range[0]), min(len(pdf_document)-1, page_range[1])\n",
    "    else:\n",
    "        start_page, end_page = 0, len(pdf_document)-1\n",
    "    \n",
    "    print(f\"Converting pages {start_page+1} to {end_page+1} of PDF\")\n",
    "    \n",
    "    images = []\n",
    "    image_paths = []\n",
    "    \n",
    "    # Process each page\n",
    "    for page_num in range(start_page, end_page+1):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        \n",
    "        # Set the resolution using dpi argument\n",
    "        zoom = dpi / 72\n",
    "        matrix = fitz.Matrix(zoom, zoom)\n",
    "        \n",
    "        # Create a pixmap (image)\n",
    "        pixmap = page.get_pixmap(matrix=matrix, alpha=False)\n",
    "        \n",
    "        # Save the image\n",
    "        output_path = os.path.join(output_dir, f\"page_{page_num + 1}.png\")\n",
    "        pixmap.save(output_path)\n",
    "        image_paths.append(output_path)\n",
    "        \n",
    "        # Also convert to PIL Image\n",
    "        img_data = pixmap.tobytes(\"png\")\n",
    "        img = Image.open(io.BytesIO(img_data))\n",
    "        images.append(img)\n",
    "        \n",
    "        print(f\"Processed page {page_num + 1}\")\n",
    "    \n",
    "    pdf_document.close()\n",
    "    \n",
    "    # Clean up temp file if created\n",
    "    if pdf_path == temp_pdf_path and os.path.exists(temp_pdf_path):\n",
    "        os.remove(temp_pdf_path)\n",
    "    \n",
    "    return images, image_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93d95b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created temporary directory: C:\\Users\\SARTHA~1\\AppData\\Local\\Temp\\tmpdkw2tcw7\n",
      "Converting pages 1 to 10 of PDF\n",
      "Processed page 1\n",
      "Processed page 2\n",
      "Processed page 3\n",
      "Processed page 4\n",
      "Processed page 5\n",
      "Processed page 6\n",
      "Processed page 7\n",
      "Processed page 8\n",
      "Processed page 9\n",
      "Processed page 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<PIL.PngImagePlugin.PngImageFile image mode=RGB size=4000x2250>,\n",
       "  <PIL.PngImagePlugin.PngImageFile image mode=RGB size=4000x2250>,\n",
       "  <PIL.PngImagePlugin.PngImageFile image mode=RGB size=4000x2250>,\n",
       "  <PIL.PngImagePlugin.PngImageFile image mode=RGB size=4000x2250>,\n",
       "  <PIL.PngImagePlugin.PngImageFile image mode=RGB size=4000x2250>,\n",
       "  <PIL.PngImagePlugin.PngImageFile image mode=RGB size=4000x2250>,\n",
       "  <PIL.PngImagePlugin.PngImageFile image mode=RGB size=4000x2250>,\n",
       "  <PIL.PngImagePlugin.PngImageFile image mode=RGB size=4000x2250>,\n",
       "  <PIL.PngImagePlugin.PngImageFile image mode=RGB size=4000x2250>,\n",
       "  <PIL.PngImagePlugin.PngImageFile image mode=RGB size=4000x2250>],\n",
       " ['C:\\\\Users\\\\SARTHA~1\\\\AppData\\\\Local\\\\Temp\\\\tmpdkw2tcw7\\\\page_1.png',\n",
       "  'C:\\\\Users\\\\SARTHA~1\\\\AppData\\\\Local\\\\Temp\\\\tmpdkw2tcw7\\\\page_2.png',\n",
       "  'C:\\\\Users\\\\SARTHA~1\\\\AppData\\\\Local\\\\Temp\\\\tmpdkw2tcw7\\\\page_3.png',\n",
       "  'C:\\\\Users\\\\SARTHA~1\\\\AppData\\\\Local\\\\Temp\\\\tmpdkw2tcw7\\\\page_4.png',\n",
       "  'C:\\\\Users\\\\SARTHA~1\\\\AppData\\\\Local\\\\Temp\\\\tmpdkw2tcw7\\\\page_5.png',\n",
       "  'C:\\\\Users\\\\SARTHA~1\\\\AppData\\\\Local\\\\Temp\\\\tmpdkw2tcw7\\\\page_6.png',\n",
       "  'C:\\\\Users\\\\SARTHA~1\\\\AppData\\\\Local\\\\Temp\\\\tmpdkw2tcw7\\\\page_7.png',\n",
       "  'C:\\\\Users\\\\SARTHA~1\\\\AppData\\\\Local\\\\Temp\\\\tmpdkw2tcw7\\\\page_8.png',\n",
       "  'C:\\\\Users\\\\SARTHA~1\\\\AppData\\\\Local\\\\Temp\\\\tmpdkw2tcw7\\\\page_9.png',\n",
       "  'C:\\\\Users\\\\SARTHA~1\\\\AppData\\\\Local\\\\Temp\\\\tmpdkw2tcw7\\\\page_10.png'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# Add project root to sys.path if not already done\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "import config # Import the config module\n",
    "\n",
    "# Use PDF path from config\n",
    "pdf_file = config.DEFAULT_PDF_PATH\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(pdf_file):\n",
    "    print(f\"Error: PDF file not found at '{pdf_file}'. Check config.py.\")\n",
    "else:\n",
    "    # Call the function with the path from config\n",
    "    try:\n",
    "        images, paths = pdf_to_screenshots_for_spaces(pdf_file)\n",
    "        print(f\"Generated {len(images)} images.\")\n",
    "    except NameError:\n",
    "        print(\"Error: pdf_to_screenshots_for_spaces function not defined in this scope.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during PDF conversion: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9943fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell remains empty or can be used for further testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc3211b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SarthakPandey\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing text generation with model: gemini-1.5-pro-latest\n",
      "Using model: gemini-1.5-pro-latest\n",
      "Sending prompt: Summarize the following text in one sentence:\n",
      "Processing content (length: 274 chars)\n",
      "\n",
      "--- Text Generator Response ---\n",
      "Generative AI models, trained on massive datasets, can understand and create human-like text, code, and images for diverse applications.\n",
      "\n",
      "\n",
      "--- Text Generator Response ---\n",
      "Generative AI models, trained on massive datasets, can understand and create human-like text, code, and images for diverse applications.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# Ensure project root is in sys.path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "try:\n",
    "    # Reload the module to get the updated function\n",
    "    import importlib\n",
    "    import src.core.generators.text_generator\n",
    "    importlib.reload(src.core.generators.text_generator)\n",
    "    from src.core.generators.text_generator import generate_text_response\n",
    "    import config # Needed for model selection and API key check within the function\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing text_generator: {e}\")\n",
    "    print(\"Ensure the file exists at 'src/core/generators/text_generator.py' and sys.path is correct.\")\n",
    "    generate_text_response = None # Prevent NameError later\n",
    "\n",
    "if generate_text_response:\n",
    "    # --- Test Data ---\n",
    "    test_system_prompt = \"You are a helpful assistant that summarizes text concisely.\"\n",
    "    test_user_prompt = (\"Please summarize the following content in exactly one sentence: \\n\\n\" \n",
    "                      \"Generative AI models, like those developed by Google and OpenAI, \"\n",
    "                      \"are capable of understanding and generating human-like text, code, and images. \"\n",
    "                      \"They are trained on vast datasets and can be used for various applications, \"\n",
    "                      \"including content creation, translation, and analysis.\")\n",
    "\n",
    "    # --- Call the Function ---\n",
    "    # Use the default model specified in config.py\n",
    "    print(f\"Testing text generation with model: {config.DEFAULT_GEMINI_PRO_MODEL}\")\n",
    "    try:\n",
    "        # Call with separate system and user prompts\n",
    "        response = generate_text_response(test_system_prompt, test_user_prompt)\n",
    "\n",
    "        # --- Print the Result ---\n",
    "        if response:\n",
    "            print(\"\\n--- Text Generator Response ---\")\n",
    "            print(response)\n",
    "        else:\n",
    "            print(\"\\nFailed to get a text response.\")\n",
    "    except Exception as e:\n",
    "         print(f\"An error occurred during the test: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c046e6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c73ad61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling model 'gemini-experimental-image-gen' with prompt: 'Generate an image of a robot reading a book in a library.'\n",
      "\n",
      "An error occurred: 404 models/gemini-experimental-image-gen is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "Make sure the model 'gemini-experimental-image-gen' exists and is accessible with your key for this purpose.\n",
      "\n",
      "An error occurred: 404 models/gemini-experimental-image-gen is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
      "Make sure the model 'gemini-experimental-image-gen' exists and is accessible with your key for this purpose.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# This model name is not a standard publicly documented model accessible\n",
    "# via the google-generativeai library for image generation with a generic key.\n",
    "# The code demonstrates the structure, but it will likely fail\n",
    "# because the model doesn't exist or doesn't support this use case via this API.\n",
    "MODEL_NAME = 'gemini-experimental-image-gen' # Replace with actual experimental model name if known and accessible\n",
    "\n",
    "try:\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"GOOGLE_API_KEY environment variable not set.\")\n",
    "    genai.configure(api_key=api_key)\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Please set the GOOGLE_API_KEY environment variable.\")\n",
    "    sys.exit(1)\n",
    "except ImportError:\n",
    "    print(\"Error: Required libraries not found.\")\n",
    "    print(\"Please run: pip install google-generativeai\")\n",
    "    sys.exit(1)\n",
    "\n",
    "def attempt_image_generation(prompt: str):\n",
    "    try:\n",
    "        model = genai.GenerativeModel(MODEL_NAME)\n",
    "        print(f\"Calling model '{MODEL_NAME}' with prompt: '{prompt}'\")\n",
    "\n",
    "        # This is the standard method. The response structure for image output\n",
    "        # from a text prompt is undefined for typical Gemini models via this library.\n",
    "        response = model.generate_content(prompt)\n",
    "\n",
    "        # Print the full response object to inspect its structure\n",
    "        print(\"\\n--- Full Response Object ---\")\n",
    "        print(response)\n",
    "        print(\"--------------------------\")\n",
    "\n",
    "        # You would need logic here to parse the response if it\n",
    "        # hypothetically contained image data (e.g., base64 or bytes).\n",
    "        # This is highly dependent on the *actual* experimental model's\n",
    "        # output format, which is not standard for gemini-pro etc.\n",
    "\n",
    "        try:\n",
    "            print(\"\\n--- Response Text Content (if any) ---\")\n",
    "            print(response.text)\n",
    "            print(\"-------------------------------------\")\n",
    "        except Exception:\n",
    "            print(\"\\nResponse object does not contain easily accessible text (.text property).\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred: {e}\")\n",
    "        print(f\"Make sure the model '{MODEL_NAME}' exists and is accessible with your key for this purpose.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_prompt = \"Generate an image of a robot reading a book in a library.\"\n",
    "    attempt_image_generation(test_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d312c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request to: https://api.friendli.ai/dedicated/o4bklt7bj3w6/v1/images/generations\n",
      "Payload: {'model': 'o4bklt7bj3w6', 'prompt': 'A futuristic cityscape at sunset, digital art', 'num_inference_steps': 10, 'n': 1, 'size': '1024x1024', 'response_format': 'b64_json'}\n",
      "Headers: {'Authorization': 'Bearer ***', 'X-Friendli-Team': 'L0578lMYXTdk', 'Content-Type': 'application/json'}\n",
      "Error making request to Friendli API: 404 Client Error: Not Found for url: https://api.friendli.ai/dedicated/o4bklt7bj3w6/v1/images/generations\n",
      "Status Code: 404\n",
      "Response Body: {'detail': 'Not Found'}\n",
      "Error making request to Friendli API: 404 Client Error: Not Found for url: https://api.friendli.ai/dedicated/o4bklt7bj3w6/v1/images/generations\n",
      "Status Code: 404\n",
      "Response Body: {'detail': 'Not Found'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "import sys\n",
    "\n",
    "# --- Configuration ---\n",
    "# Friendli API Credentials\n",
    "FRIENDLI_TOKEN = \"flp_TQQqSUhYVNzgCTO9zXyAJpZWciaDoDm57ECzb1EoNgx68\" # Replace with your actual token or load from env\n",
    "FRIENDLI_TEAM_ID = \"L0578lMYXTdk\" # Replace with your actual team ID or load from env\n",
    "FRIENDLI_ENDPOINT_ID = \"o4bklt7bj3w6\" # Your dedicated endpoint ID\n",
    "FRIENDLI_ENDPOINT_URL = f\"https://api.friendli.ai/dedicated/{FRIENDLI_ENDPOINT_ID}/v1/images/generations\" # Updated URL\n",
    "\n",
    "def generate_image_with_friendli(prompt: str):\n",
    "    \"\"\"Generates an image using the Friendli AI dedicated endpoint.\"\"\"\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {FRIENDLI_TOKEN}\", # Added Authorization Header\n",
    "        \"X-Friendli-Team\": FRIENDLI_TEAM_ID, # Added Team ID Header\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    # Payload structure based on reference, using endpoint ID as model\n",
    "    payload = {\n",
    "        \"model\": FRIENDLI_ENDPOINT_ID, # Use endpoint ID as model identifier\n",
    "        \"prompt\": prompt,\n",
    "        \"num_inference_steps\": 10, # Added based on reference\n",
    "        \"n\": 1,  # Kept from previous version\n",
    "        \"size\": \"1024x1024\", # Kept from previous version\n",
    "        \"response_format\": \"b64_json\" # Kept from previous version\n",
    "        # Add other parameters like 'negative_prompt', 'style_raw' etc. if needed\n",
    "    }\n",
    "\n",
    "    print(f\"Sending request to: {FRIENDLI_ENDPOINT_URL}\")\n",
    "    print(f\"Payload: {payload}\")\n",
    "    print(f\"Headers: {{'Authorization': 'Bearer ***', 'X-Friendli-Team': '{FRIENDLI_TEAM_ID}', 'Content-Type': 'application/json'}}\") # Print headers safely\n",
    "\n",
    "    try:\n",
    "        response = requests.post(FRIENDLI_ENDPOINT_URL, headers=headers, json=payload)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)\n",
    "\n",
    "        response_data = response.json()\n",
    "\n",
    "        # Check the structure of the response - this depends on the API\n",
    "        if 'data' in response_data and len(response_data['data']) > 0 and 'b64_json' in response_data['data'][0]:\n",
    "            b64_image_data = response_data['data'][0]['b64_json']\n",
    "            image_bytes = base64.b64decode(b64_image_data)\n",
    "            img = Image.open(io.BytesIO(image_bytes))\n",
    "            print(\"Image generated successfully!\")\n",
    "            return img\n",
    "        else:\n",
    "            print(\"Error: Unexpected response format from Friendli API.\")\n",
    "            print(\"Response JSON:\", response_data)\n",
    "            return None\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error making request to Friendli API: {e}\")\n",
    "        if hasattr(e, 'response') and e.response is not None:\n",
    "            print(f\"Status Code: {e.response.status_code}\")\n",
    "            try:\n",
    "                print(f\"Response Body: {e.response.json()}\")\n",
    "            except requests.exceptions.JSONDecodeError:\n",
    "                print(f\"Response Body: {e.response.text}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\": \n",
    "    test_prompt = \"A futuristic cityscape at sunset, digital art\"\n",
    "    generated_image = generate_image_with_friendli(test_prompt)\n",
    "\n",
    "    if generated_image:\n",
    "        # In a notebook, displaying the image is often desired\n",
    "        # generated_image.show() # Uncomment to display directly if environment supports it\n",
    "        # Or save it\n",
    "        try:\n",
    "            save_path = \"friendli_generated_image.png\"\n",
    "            generated_image.save(save_path)\n",
    "            print(f\"Image saved to {os.path.abspath(save_path)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving image: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe886f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linkgenix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
